{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#writer = pd.ExcelWriter('output.xlsx')\n",
    "#occ_data.to_excel(writer,'Sheet1')\n",
    "#writer.save()\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import required Libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "#read in the data files\n",
    "files = os.listdir(\"/Users/student/Desktop/Capstone/Data\")\n",
    "\n",
    "#change working directory to where the excel files are\n",
    "os.chdir('C:\\\\Users\\\\student\\\\Desktop\\\\Capstone\\\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AsianF.xls\n",
      "AsianM.xls\n",
      "BlackF.xls\n",
      "BlackM.xls\n",
      "census_final.xlsx\n",
      "HawaiianF.xls\n",
      "HawaiianM.xls\n",
      "HispanicF.xls\n",
      "HispanicM.xls\n",
      "IndianF.xls\n",
      "IndianM.xls\n",
      "other\n",
      "OtherF.xls\n",
      "OtherM.xls\n",
      "output.xlsx\n",
      "TotalF.xls\n",
      "TotalM.xls\n",
      "TwoRaceF.xls\n",
      "TwoRaceM.xls\n",
      "WhiteF.xls\n",
      "WhiteM.xls\n"
     ]
    }
   ],
   "source": [
    "#check to make sure read in worked\n",
    "for i in range(len(files)):\n",
    "    print (files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a list of the dataset names\n",
    "dataset_names=[]\n",
    "\n",
    "for i in range(len(files)):\n",
    "    dataset_names.append(files[i][:files[i].find(\".\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a dictionary with the dataset name and the actual data file\n",
    "cenus_data={}\n",
    "\n",
    "#range(len(dataset_names))\n",
    "for i in range(len(dataset_names)):\n",
    "    if(files[i][-3:]==\"xls\"):\n",
    "      cenus_data[dataset_names[i]]=pd.read_excel(files[i])\n",
    "\n",
    "    #at this point have all the occupation data sets in a dictionary with the name and then the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AsianF', 'AsianM', 'BlackF', 'BlackM', 'HawaiianF', 'HawaiianM', 'HispanicF', 'HispanicM', 'IndianF', 'IndianM', 'OtherF', 'OtherM', 'TotalF', 'TotalM', 'TwoRaceF', 'TwoRaceM', 'WhiteF', 'WhiteM'])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure dictionary worked\n",
    "cenus_data.keys()\n",
    "\n",
    "#pull the actual data set in the dictionary\n",
    "#cenus_data[list(cenus_data.keys())[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reassign the column names as the name of the dataset PLUS the current column name\n",
    "\n",
    "#list of the columns that we want\n",
    "female_columns=['NAME','PCT086130', 'PCT086143','PCT086181','PCT086216','PCT086219']\n",
    "male_columns=['NAME','PCT086004', 'PCT086017','PCT086055','PCT086090','PCT086093']\n",
    "\n",
    "for x in range(len(cenus_data)):\n",
    "    new_col_names=[]\n",
    "    \n",
    "    #check to see if it is a male or female data set\n",
    "    #create a temp table called final that contains only the variables in the female/male columns list along with name\n",
    "    if(list(cenus_data.keys())[x][-1:]=='F'):\n",
    "        for i in range(0,len(female_columns)):\n",
    "            if(i==0):\n",
    "                final=cenus_data[list(cenus_data.keys())[x]].filter(regex=female_columns[i])\n",
    "            else:\n",
    "                temp2 = cenus_data[list(cenus_data.keys())[x]].filter(regex=female_columns[i])\n",
    "                final=pd.concat([final,temp2],axis=1)\n",
    "    else:\n",
    "        for i in range(0,len(male_columns)):\n",
    "            if(i==0):\n",
    "                final=cenus_data[list(cenus_data.keys())[x]].filter(regex=male_columns[i])\n",
    "            else:\n",
    "                temp2 = cenus_data[list(cenus_data.keys())[x]].filter(regex=male_columns[i])\n",
    "                final=pd.concat([final,temp2],axis=1)\n",
    "                \n",
    "    #assign the temp data set to the corresponding spot in the census data list            \n",
    "    cenus_data[list(cenus_data.keys())[x]]=final\n",
    "\n",
    "    #keep the first two columns the same name: county number and name\n",
    "    #for all the other columns add the data set name infront of it\n",
    "    for i in range(len(final.columns)):\n",
    "        if(i<1):\n",
    "            new_col_names.append(final.columns[i])\n",
    "        else:\n",
    "            new_col_names.append(list(cenus_data.keys())[x]+\"_\"+final.columns[i])\n",
    "    #end the loop changing column names\n",
    "        \n",
    "    #assign the newly created column name list to the dataset\n",
    "    cenus_data[list(cenus_data.keys())[x]].columns=new_col_names\n",
    "\n",
    "#end loop going through each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all the datasets in the cenus_data dictionary into one\n",
    "\n",
    "occ_data=cenus_data[list(cenus_data.keys())[len(cenus_data)-1]]\n",
    "    \n",
    "for x in range(0,len(cenus_data)-1):\n",
    "    occ_data=pd.merge(occ_data,cenus_data[list(cenus_data.keys())[x]],how=\"left\",on=\"NAME\")\n",
    "    \n",
    "#remove the duplicate county variable    \n",
    "#occ_data=occ_data.drop([\"COUNTY_x\",\"COUNTY_y\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start reading in and cleaning up the income statistics dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "income=pd.read_excel(\"/Users/student/Desktop/Capstone/Data/other/income_statistics.xls\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove first two rows\n",
    "income=income.loc[2:]\n",
    "\n",
    "#if a value in the first row is blank change it to the first value to the left\n",
    "for i in range(len(income.columns)):\n",
    "    if(type(income.iat[0,i])!=str and math.isnan(income.iat[0,i])):\n",
    "        income.iat[0,i]=income.iat[0,i-1]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combine the first and second row and make that the column headers\n",
    "#loop through the number of columns\n",
    "col_names=[]\n",
    "for i in range(len(income.columns)):\n",
    "    #if the second row is blank then add just the first row\n",
    "    if(type(income.iat[1,i])!=str and math.isnan(income.iat[1,i])):\n",
    "        col_names.append(income.iat[0,i])\n",
    "    #if the second row isnot blank then combine the first and second row\n",
    "    else:\n",
    "        col_names.append(income.iat[0,i]+\"_\"+income.iat[1,i])\n",
    "        \n",
    "#assign the new column names\n",
    "income.columns=col_names\n",
    "\n",
    "#delete the first two rows which are now the column names\n",
    "income=income.drop(income.index[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#delete blanks, 99999 and 0 in zip code column\n",
    "\n",
    "#delete if first column is blank\n",
    "income = income[pd.notnull(income.iloc[:,0])]\n",
    "#income = income[pd.notnull(income.iloc[:,1])]\n",
    "\n",
    "#delete zip codes of 0\n",
    "income=income[income.iloc[:,0] != 0]\n",
    "\n",
    "#delete zip codes of 99999\n",
    "income=income[income.iloc[:,0] != 99999]\n",
    "\n",
    "#delete rows with a missing number of returns. This gets rid of non zip codes in first column\n",
    "income = income[pd.notnull(income.iloc[:,2])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create the number of returns in each income bracket columns\n",
    "\n",
    "one_25=income[income.iloc[:,1] == '$1 under $25,000'].iloc[:,:3]\n",
    "one_25=one_25.drop(\"Size of adjusted gross income\",axis=1)\n",
    "one_25=one_25.rename(columns = {'Number of returns':'$1 under $25,000 Number of Returns'})\n",
    "\n",
    "twentyfive_50=income[income.iloc[:,1] == '$25,000 under $50,000'].iloc[:,:3]\n",
    "twentyfive_50=twentyfive_50.drop(\"Size of adjusted gross income\",axis=1)\n",
    "twentyfive_50=twentyfive_50.rename(columns = {'Number of returns':'$25,000 under $50,000 Number of Returns'})\n",
    "\n",
    "fifty_75=income[income.iloc[:,1] == '$50,000 under $75,000'].iloc[:,:3]\n",
    "fifty_75=fifty_75.drop(\"Size of adjusted gross income\",axis=1)\n",
    "fifty_75=fifty_75.rename(columns = {'Number of returns':'$50,000 under $75,000 Number of Returns'})\n",
    "\n",
    "seventyfive_100=income[income.iloc[:,1] == '$75,000 under $100,000'].iloc[:,:3]\n",
    "seventyfive_100=seventyfive_100.drop(\"Size of adjusted gross income\",axis=1)\n",
    "seventyfive_100=seventyfive_100.rename(columns = {'Number of returns':'$75,000 under $100,000 Number of Returns'})\n",
    "\n",
    "hundo_200=income[income.iloc[:,1] == '$100,000 under $200,000'].iloc[:,:3]\n",
    "hundo_200=hundo_200.drop(\"Size of adjusted gross income\",axis=1)\n",
    "hundo_200=hundo_200.rename(columns = {'Number of returns':'$100,000 under $200,000 Number of Returns'})\n",
    "\n",
    "twohundo_up=income[income.iloc[:,1] == '$200,000 or more'].iloc[:,:3]\n",
    "twohundo_up=twohundo_up.drop(\"Size of adjusted gross income\",axis=1)\n",
    "twohundo_up=twohundo_up.rename(columns = {'Number of returns':'$200,000 or more Number of Returns'})\n",
    "\n",
    "\n",
    "#merge these with the income dataset to create them in columns\n",
    "income=pd.merge(income,one_25,left_on=\"ZIP\\ncode [1]\", right_on=\"ZIP\\ncode [1]\", how=\"left\")\n",
    "\n",
    "income=pd.merge(income,twentyfive_50,left_on=\"ZIP\\ncode [1]\", right_on=\"ZIP\\ncode [1]\", how=\"left\")\n",
    "\n",
    "income=pd.merge(income,fifty_75,left_on=\"ZIP\\ncode [1]\", right_on=\"ZIP\\ncode [1]\", how=\"left\")\n",
    "\n",
    "income=pd.merge(income,seventyfive_100,left_on=\"ZIP\\ncode [1]\", right_on=\"ZIP\\ncode [1]\", how=\"left\")\n",
    "\n",
    "income=pd.merge(income,hundo_200,left_on=\"ZIP\\ncode [1]\", right_on=\"ZIP\\ncode [1]\", how=\"left\")\n",
    "\n",
    "income=pd.merge(income,twohundo_up,left_on=\"ZIP\\ncode [1]\", right_on=\"ZIP\\ncode [1]\", how=\"left\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#delete everything besides the total row\n",
    "income = income[-pd.notnull(income.iloc[:,1])]\n",
    "\n",
    "#remove the gross income column\n",
    "income=income.drop(\"Size of adjusted gross income\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#conver all columns to ints\n",
    "income=income.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#match the county with the zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load in the zip codes file\n",
    "zip_codes=pd.read_excel(\"/Users/student/Desktop/Capstone/Data/other/zip_codes.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merge the income and zip code file together\n",
    "income=pd.merge(income,zip_codes,left_on=income.iloc[:,0],right_on=zip_codes.iloc[:,0])\n",
    "income=income.drop([\"ZIP\\ncode [1]\", 'ZIP Code'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#summarize the variables by county\n",
    "\n",
    "income=income.groupby(\"County\",as_index=False).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merge the occupation and income datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove county from the name in occupation\n",
    "for i in range(len(occ_data)):\n",
    "    occ_data[\"NAME\"][i]=occ_data[\"NAME\"][i].replace(\" County\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#actually merge the occupation and income datasets\n",
    "\n",
    "census=pd.merge(occ_data,income, left_on=\"NAME\",right_on=\"County\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "census=census.drop(['County'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('output.xlsx')\n",
    "census.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
